# Rule By Example: Harnessing Logical Rules for Explainable Hate Speech Detection
This repository contains information on the ACL'23 Main Conference paper **Rule By Example: Harnessing Logical Rules for Explainable Hate Speech Detection** by ***Christopher Clarke, Matthew Hall, Gaurav Mittal, Ye Yu, Sandra Sajeev, Jason Mars and Mei Chen***

Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. However, while rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and do not have the flexibility or robustness to moderate the vast amount of undesirable content found online. Recent advances in deep learning have introduced the use of highly effective deep neural models capable of overcoming these challenges. In contrast, despite the improved performance introduced by these data-driven models, they lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms. In this paper, we present **Rule By Example (RBE)**: a novel exemplar-based contrastive learning approach for learning from logical rules for the task of textual content moderation. RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches. **Data & paper coming soon!**
